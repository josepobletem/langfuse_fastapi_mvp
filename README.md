
# Langfuse + FastAPI Demo (Good Practices)

Proyecto mÃ­nimo con **FastAPI**, **OpenAI** y **Langfuse** para observabilidad de apps con LLM,
siguiendo buenas prÃ¡cticas: configuraciÃ³n por entorno, logging, validaciÃ³n con Pydantic, salud,
tests bÃ¡sicos, Docker y docker-compose.

## ğŸ§± Estructura
```
.
â”œâ”€ src/
â”‚  â”œâ”€ app.py         # API FastAPI + endpoints /health y /ask
â”‚  â”œâ”€ config.py      # Settings via env vars (Pydantic)
â”‚  â””â”€ obsv.py        # Wrapper de Langfuse (graceful si no hay claves)
â”œâ”€ tests/
â”‚  â””â”€ test_app.py    # Tests mÃ­nimos
â”œâ”€ .env.example      # Plantilla de variables de entorno
â”œâ”€ requirements.txt
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â”œâ”€ Makefile
â””â”€ README.md
```

## ğŸš€ Puesta en marcha

1) Crear entorno y deps:
```bash
python -m venv .venv
. .venv/bin/activate
pip install -r requirements.txt
```

2) Copiar `.env.example` a `.env` y completar:

```
OPENAI_API_KEY=sk-...
LANGFUSE_PUBLIC_KEY=pk-...
LANGFUSE_SECRET_KEY=sk-...
LANGFUSE_HOST=https://cloud.langfuse.com
APP_ENV=dev
LOG_LEVEL=INFO
PORT=8000
```

> Si no configuras Langfuse, la app funciona igual pero **no** registra trazas (wrapper graceful).

3) Ejecutar en local:
```bash
make run
# o
uvicorn src.app:app --host 0.0.0.0 --port 8000 --reload
```

- Salud: `GET http://localhost:8000/health`
- Preguntar: `POST http://localhost:8000/ask` con JSON
```json
{"user_id":"jose","question":"Â¿QuÃ© es Langfuse en una frase?"}
```

## ğŸ§ª Tests
```bash
make test
```

## ğŸ³ Docker
```bash
make docker-build
docker run -p 8000:8000 --env-file .env langfuse-fastapi-demo:latest
```

## ğŸ™ docker-compose (con Langfuse self-hosted *demo*)
```bash
docker-compose up --build
# App en :8000, Langfuse UI en :3000 (configurar credenciales segÃºn docs)
```

## âœ… Buenas prÃ¡cticas incluidas
- **12-factor config**: todo por variables de entorno; `.env.example` de guÃ­a.
- **Observabilidad**: trazas/spans/generations/scores con Langfuse (degrada a no-op si faltan claves).
- **Logging**: nivel configurable, mensajes estructurados base.
- **ValidaciÃ³n**: Pydantic en request/response; tipado.
- **Errores**: manejo de excepciÃ³n en llamada al LLM con 502 y logs.
- **Healthcheck**: endpoint `/health` para readiness/liveness.
- **Versionado de prompt**: `prompt_version` en metadata para A/B.
- **Tests**: mÃ­nimos con TestClient para health y validaciones.
- **Docker**: contenedor reproducible; compose opcional con Postgres + Langfuse UI.
- **Seguridad**: no se exponen claves en cÃ³digo; usar `.env`/secret manager en prod.

## ğŸ”’ Notas de seguridad y producciÃ³n
- Montar **rate limiting**, autenticaciÃ³n (API key/JWT) y CORS segÃºn tu caso.
- Centralizar logs en un backend (Cloud Logging, ELK, etc.).
- AÃ±adir **timeout/retry** a llamadas a LLM.
- Para RAG, loguear `document_ids` y usar **guardrails** (validaciÃ³n de formato y polÃ­ticas).
- En k8s: configurar liveness/readiness probes y recursos; usar **secrets** y **autoscaling**.

---

Desarrollado con â¤ï¸ por **JosÃ© Poblete M.** (ejemplo de buenas prÃ¡cticas para apps LLM observables con Langfuse).
